<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>ClipSAM：CLIP and SAM Collaboration for Zero-Shot Anomaly Segmentation | Just花语的博客</title><meta name="author" content="Just花语"><meta name="copyright" content="Just花语"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="[TOC] ClipSAM arxiv 2023   复旦大学，Shengze Li，Jianjian Cao，Tao Chen      CLIP + SAM 作 ZSAD CLIP粗分割，SAM细分割，本质还是SAM   1. 问题1. ZSAD（零样本异常检测）任务​	需要使用辅助数据训练的检测模型来检测异常，而目标数据集中没有任何训练样本。 2. CLIP 用于ZSAS问题 ​	CLIP主">
<meta property="og:type" content="article">
<meta property="og:title" content="ClipSAM：CLIP and SAM Collaboration for Zero-Shot Anomaly Segmentation">
<meta property="og:url" content="https://justhuayu.github.io/2024/02/21/%E7%A7%91%E7%A0%94-2-ClipSAM/index.html">
<meta property="og:site_name" content="Just花语的博客">
<meta property="og:description" content="[TOC] ClipSAM arxiv 2023   复旦大学，Shengze Li，Jianjian Cao，Tao Chen      CLIP + SAM 作 ZSAD CLIP粗分割，SAM细分割，本质还是SAM   1. 问题1. ZSAD（零样本异常检测）任务​	需要使用辅助数据训练的检测模型来检测异常，而目标数据集中没有任何训练样本。 2. CLIP 用于ZSAS问题 ​	CLIP主">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://telegraph-image-9wl.pages.dev/file/610c334d0084c2b8c8875.png">
<meta property="article:published_time" content="2024-02-21T01:00:00.000Z">
<meta property="article:modified_time" content="2024-03-19T02:53:18.095Z">
<meta property="article:author" content="Just花语">
<meta property="article:tag" content="科研">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://telegraph-image-9wl.pages.dev/file/610c334d0084c2b8c8875.png"><link rel="shortcut icon" href="https://telegraph-image-9wl.pages.dev/file/3dff73595485fb9078401.png"><link rel="canonical" href="https://justhuayu.github.io/2024/02/21/%E7%A7%91%E7%A0%94-2-ClipSAM/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'ClipSAM：CLIP and SAM Collaboration for Zero-Shot Anomaly Segmentation',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-19 10:53:18'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/modify.css"><meta name="generator" content="Hexo 7.1.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://telegraph-image-9wl.pages.dev/file/3dff73595485fb9078401.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">52</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://telegraph-image-9wl.pages.dev/file/610c334d0084c2b8c8875.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Just花语的博客"><span class="site-name">Just花语的博客</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">ClipSAM：CLIP and SAM Collaboration for Zero-Shot Anomaly Segmentation</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2024-02-21T01:00:00.000Z" title="发表于 2024-02-21 09:00:00">2024-02-21</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/">科研</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>8分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="ClipSAM：CLIP and SAM Collaboration for Zero-Shot Anomaly Segmentation"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img" style="background-image: url('https://telegraph-image-9wl.pages.dev/file/610c334d0084c2b8c8875.png');"></div><article class="post-content" id="article-container"><p>[TOC]</p>
<h1 id="ClipSAM"><a href="#ClipSAM" class="headerlink" title="ClipSAM"></a>ClipSAM</h1><blockquote>
<p>arxiv 2023</p>
</blockquote>
<blockquote>
<p>复旦大学，Shengze Li，Jianjian Cao，Tao Chen</p>
</blockquote>
<img src="https://telegraph-image-9wl.pages.dev/file/610c334d0084c2b8c8875.png" alt="image-20240220155331043" style="zoom:30%;">

<blockquote>
<ol>
<li>CLIP + SAM 作 ZSAD</li>
<li>CLIP粗分割，SAM细分割，本质还是SAM</li>
</ol>
</blockquote>
<h2 id="1-问题"><a href="#1-问题" class="headerlink" title="1. 问题"></a>1. 问题</h2><h3 id="1-ZSAD（零样本异常检测）任务"><a href="#1-ZSAD（零样本异常检测）任务" class="headerlink" title="1. ZSAD（零样本异常检测）任务"></a>1. ZSAD（零样本异常检测）任务</h3><p>​	需要使用辅助数据训练的检测模型来检测异常，而目标数据集中没有任何训练样本。</p>
<h3 id="2-CLIP-用于ZSAS问题"><a href="#2-CLIP-用于ZSAS问题" class="headerlink" title="2. CLIP 用于ZSAS问题"></a>2. CLIP 用于ZSAS问题</h3><blockquote>
<p>​	CLIP主要关注不同输入之间的全局特征对齐，==导致局部异常部分的分割不精确==。</p>
</blockquote>
<h3 id="3-SAM-用于ZSAS问题"><a href="#3-SAM-用于ZSAS问题" class="headerlink" title="3. SAM 用于ZSAS问题"></a>3. SAM 用于ZSAS问题</h3><blockquote>
<p>​	SAM会==产生大量冗余掩码==，==需要合适的提示==。==简单的文本提示不能有效描述异常区域==，导致异常定位性能欠佳，SAM功能利用率不足。同时，==模糊的提示会产生冗余的掩码==。</p>
</blockquote>
<h2 id="2-创新"><a href="#2-创新" class="headerlink" title="2. 创新"></a>2. 创新</h2><h3 id="1-CLIP-和-SAM-协同"><a href="#1-CLIP-和-SAM-协同" class="headerlink" title="1. CLIP 和 SAM 协同"></a>1. CLIP 和 SAM 协同</h3><blockquote>
<p>​	CLIP进行==异常定位和粗分割==，SAM利用定位和粗分割结果进行==细分割==。</p>
</blockquote>
<h3 id="2-统一多尺度跨模态交互-UMCI-模块"><a href="#2-统一多尺度跨模态交互-UMCI-模块" class="headerlink" title="2.  统一多尺度跨模态交互(UMCI)模块"></a>2.  统一多尺度跨模态交互(UMCI)模块</h3><blockquote>
<p>​	UMCI (Unified Multi-scale Cross-modal Interaction) 实现CLIP==不同层次的多模态特征融合==，以获得异常定位和粗分割。</p>
</blockquote>
<p>​	UMCI将==水平方向和垂直方向==的图像 patch tokens 聚合，并利用==相应的行、列特征与 text 特征交互==，感知不同方向的局部异常。UMCI还考虑了语言和多尺度视觉特征的相互作用。</p>
<p>​	该模块通过在==行-列和多尺度级别==上的语言特征与视觉特征交互来学习异常部件的局部和全局语义。</p>
<h3 id="3-多级掩码细化-MMR-模块"><a href="#3-多级掩码细化-MMR-模块" class="headerlink" title="3. 多级掩码细化(MMR)模块"></a>3. 多级掩码细化(MMR)模块</h3><blockquote>
<p>​	MMR (Multi-level Mask Refinement) 利用CLIP的定位信息来指导SAM进行分割细化	</p>
</blockquote>
<p>​	首先从CLIP的异常定位结果中==提取不同的点和边界框==提示，然后使用这些提示来==指导SAM生成==精确的掩码。最后，将这些==掩码与基于不同掩码置信度的CLIP结果融合==。</p>
<h2 id="3-方法"><a href="#3-方法" class="headerlink" title="3. 方法"></a>3. 方法</h2><h3 id="1-CLIP-部分"><a href="#1-CLIP-部分" class="headerlink" title="1.CLIP 部分"></a>1.CLIP 部分</h3><img src="https://telegraph-image-9wl.pages.dev/file/394ad1f18de0a39c09f69.png" alt="image-20240221100305823" style="zoom:30%;">

<p>​	主要关注==提示词==的设计，对于上图中CLIP Text的两个输入：</p>
<ol>
<li>上面输入，表示有 $n$ 个==描述短语==。</li>
<li>左边输入，表示有 $m_{normal}$ 个==描述正常状态的词==， $m_{abnormal}$ 个==描述异常状态的词==。</li>
<li>对于==同一类==（类==默认已知==，未知类用==[object]站位==），总有 $n \times (m_{normal} + m_{abnormal})$ 个==提示句子==。</li>
<li>所有句子通过CLIP Text，计算文本特征==平均值==。</li>
</ol>
<h3 id="2-统一多尺度跨模态交互-UMCI-模块-1"><a href="#2-统一多尺度跨模态交互-UMCI-模块-1" class="headerlink" title="2.统一多尺度跨模态交互(UMCI)模块"></a>2.统一多尺度跨模态交互(UMCI)模块</h3><img src="https://telegraph-image-9wl.pages.dev/file/028a98e00e7ca82792078.png" alt="image-20240221100638886" style="zoom:41%;">

<blockquote>
<p>​	UMCI模块的输入为CLIP编码器处理后得到的文本特征 $L$ （与WinCLIP一致）和第 $i$ 阶段生成的 patch tokens $P_i$ 。</p>
</blockquote>
<p>​	UMCI模型由两条并行路径组成：==条形路径(Strip Path)和比例路径(Scale Path)==。Strip Path捕获 patch tokens 的==行级和列级特征==，==以精确定位位置==。Scale Path 侧重于掌握图像的==各种尺度的全局特征==，从而全面了解异常。</p>
<ol>
<li>==Strip path== 条形路径、 ==Scale path== 比例路径，算法中 $B(.)$ 指双线性插值。</li>
</ol>
<div style="display:flex; justify-content:space-between;">
  <img src="https://telegraph-image-9wl.pages.dev/file/c1d36198d0ebcdf6612e9.png" alt="image-20240221130203205" style="width: 48%;">
  <img src="https://telegraph-image-9wl.pages.dev/file/2f1978ec8967f2947e030.png" alt="image-20240221130246384" style="width: 48%;">
</div>

<ol start="2">
<li>输出==最终结果==。</li>
</ol>
<p>$$<br>v_{ori} = {conv}_{ori}^{3 \times 3}(\hat{P})<br>$$</p>
<p>$$<br>M_{all} = {conv}<em>{all}^{3 \times 3}({concat}(v</em>{ori}, M_{row,col}, M_{g_1}, M_{g_2}))<br>$$</p>
<p>$$<br>O = {MLP}({ReLU}(M_{all} + \hat{P}))<br>$$</p>
<ol start="3">
<li>如果编码器中==有 $n$ 个阶段==，将第 $i$ 阶段的分割输出设为 $O_i$ ，则==最终的分割结果==可计算为。</li>
</ol>
<p>$$<br>O = \frac{1}{n} \sum_{i=1}^{n} O_i<br>$$</p>
<h3 id="3-SAM部分，多级掩码细化-MMC"><a href="#3-SAM部分，多级掩码细化-MMC" class="headerlink" title="3. SAM部分，多级掩码细化(MMC)"></a>3. SAM部分，多级掩码细化(MMC)</h3><img src="https://telegraph-image-9wl.pages.dev/file/a28dbdcfac76ca5f7113c.png" alt="image-20240221103130908" style="zoom:40%;">

<blockquote>
<p>​	MMC 的输入为 CLIP处理后的==定位信息和粗分割==，该模块流程如下：</p>
</blockquote>
<ol>
<li>根据输入，获得==二进制掩码==，==1 表示异常像素点==。</li>
</ol>
<p>$$<br>v(x, y)_b =<br>\begin{cases}<br>1, &amp; \text{if } v(x, y)_f &gt; \text{threshold} \<br>0, &amp; \text{otherwise}<br>\end{cases}<br>$$</p>
<ol start="2">
<li>生成==点提示==。随机选择 $m$ 个点，$(x_{pm}, y_{pm})$ 表示第 $i$ 个点位置。</li>
</ol>
<p>$$<br>S_p = \left[ (x_{p1}, y_{p1}), \ldots, (x_{pm}, y_{pm}) \right],<br>$$</p>
<ol start="3">
<li>生成==框提示==。根据二进制掩码中==连通区域的大小==和==第 $i$ 个点位置==，生成 $q$ 个方框。</li>
</ol>
<p>$$<br>S_{b_i} = \left[ (x_{b_i}, y_{b_i}, h_{b_i}, w_{b_i}) \right]，<br>{S}<em>{b} = [{S}</em>{b_1}, \ldots, {S}_{b_q}]<br>$$</p>
<blockquote alt="info">
    <p>
        消融实验：点提示和框提示的有效性。
    </p>
</blockquote>

<img src="https://telegraph-image-9wl.pages.dev/file/5e0b58ad16f56d91d70f1.png" alt="image-20240221110923658" style="zoom:70%;">

<ol start="4">
<li>使用 SAM 分割原始图像。输入是==原始图像和提示 $S$== ，==编码后特征为 $Z_i$和$Z_S$==，解码后结果为==掩码 $masks$ 和相应的置信度分数 $scores$==。SAM 为每个框提示生成三个具有不同置信度分数的掩码。</li>
</ol>
<p>$$<br>S = S_b \cup S_p<br>$$</p>
<p>$$<br>({masks}, {scores}) = D_{sam}(z_i | z_s).<br>$$</p>
<p>$$<br>\text{masks} = \left[<br>\begin{array}{ccc}<br>m_{1}^1 &amp; m_{1}^2 &amp; m_{1}^3 \<br>\vdots &amp; \vdots &amp; \vdots \<br>m_{q}^1 &amp; m_{q}^2 &amp; m_{q}^3 \<br>\end{array}<br>\right], \quad \text{scores} = \left[<br>\begin{array}{ccc}<br>s_{1}^1 &amp; s_{1}^2 &amp; s_{1}^3 \<br>\vdots &amp; \vdots &amp; \vdots \<br>s_{q}^1 &amp; s_{q}^2 &amp; s_{q}^3 \<br>\end{array}<br>\right]<br>$$</p>
<ol start="5">
<li>SAM 结果与原始输入叠加，得到==最终结果==。</li>
</ol>
<p>$$<br>O_{final} = {Norm}\left(O + \sum_{i=1}^{q} \sum_{j=1}^{3} m_{i}^j \times s_{i}^j\right)<br>$$</p>
<h3 id="4-损失函数"><a href="#4-损失函数" class="headerlink" title="4. 损失函数"></a>4. 损失函数</h3><blockquote>
<p>使用 Focal loss 和 Mice loss</p>
</blockquote>
<p>$$<br>L_{focal} = -\frac{1}{H \times W} \sum_{i=0}^{H \times W} (1 - p_i)^\gamma \log(p_i)，\gamma = 2<br>$$</p>
<p>$$<br>L_{dice} = 1 - \frac{2 \times \sum_{i=1}^{N} y_i \hat{y}<em>i}{\sum</em>{i=1}^{N} y_i^2 + \sum_{i=1}^{N} \hat{y}_i^2}  ，N = H \times W<br>$$</p>
<p>$$<br>L_{all} = \sum_{i=1}^{n} \lambda_i (L_{focal}^i + L_{dice}^i),<br>$$</p>
<p>​	$λ_i$ 为第 $i$ 阶段的损失权值。CLIP编码器本文总共由4个阶段组成，$λ_i$ 分别为 ==0.1、0.1、0.1和0.7==。</p>
<h2 id="4-结果"><a href="#4-结果" class="headerlink" title="4. 结果"></a>4. 结果</h2><img src="https://telegraph-image-9wl.pages.dev/file/164cbfacd619c4499eba5.png" alt="image-20240221104522472" style="zoom:60%;">

<blockquote>
<p>$AUROC$ 接收者特性曲线下方的面积</p>
</blockquote>
<p>​	AUROC (area under the receiver operating characteristic) 接收者特性曲线下方的面积，==AUROC值越大，正确率越高==。AUROC 衡量模型在区分两个类别（如正类和负类）方面的能力，其中 $AUROC = 0.5$ 表示随机猜测。</p>
<p>​	横坐标是==假正率==（False Positive Rate, FPR），纵坐标是==真正率==（True Positive Rate, TPR）。<br>$$<br>FRR = \frac{FN}{FN + TP} = \frac{假阳性数量}{实际阴性样本总数}<br>$$</p>
<p>$$<br>TPR = \frac{TP}{TP + FN}=\frac{真阳性数量}{实际阳性样本总数}<br>$$</p>
<blockquote>
<p>$F_1-max$ 在不同的决策阈值或不同的条件下，F1分数的最大值</p>
</blockquote>
<p>​	F1分数（F1-Score）是一个用于衡量二分类模型性能的指标，它是模型==精确率（Precision）和召回率（Recall）的调和平均数==。F1分数的范围从0到1，1表示完美的精确率和召回率，0表示至少有一个为零。<br>$$<br>F_{1{-max}} = \max \left(2 \times \frac{Precision} \times {Recall}{Precision} + {Recall}\right)<br>$$</p>
<p>$$<br>{Precision} = \frac{TP}{TP + FP}<br>$$</p>
<p>$$<br>\text{Recall} = \frac{TP}{TP + FN}<br>$$</p>
<blockquote>
<p>$AP$ 平均精度</p>
</blockquote>
<p>​	AP (Average Precision) 平均精度是==对精确率（Precision）在不同召回率（Recall）阈值下的表现进行平均的结果==。AP考虑了模型在==所有可能的分类阈值下的性能==，因此是一个衡量模型整体性能的有力指标。<br>$$<br>AP = \frac{1}{正例总数} \sum_{k=1}^{n} (P(k) \times {rel}(k))<br>$$<br>​	其中 $n$ 是返回结果的数量，$P(k)$ 是在前 $k$ 个返回结果中的精确率，$\text{rel}(k)$ 是一个指示函数，如果第 $k$ 个结果是正例，则为 $1$，否则为 $0$。</p>
<blockquote>
<p>$PRO$ (per-region-overlap)</p>
</blockquote>
<p>​	PRO评价模型识别出的==异常或目标区域与实际的异常或目标区域的匹配精度==。<br>$$<br>PRO = \frac{1}{N} \sum_{n=1}^{N} \frac{P \cap G_n}{G_n} = \frac{1}{N} \sum_{n=1}^{N} \frac{TP_n}{TP_n + FN_n}<br>$$<br>​	定位的缺陷结果和实际的真值按连通域划分为 $N$ 个区域，接着求出每个区域中预测结果 $P$ 和真值 $G_n$ 的交集，将交集除以 $G_n$ 后 $N$ 个区域加权平均即可求得 $PRO$ 值 。同时预测结果 $P$ 和真值 $G_n$ 的交集即真阳性样本 $TP_n$ ，故 $PRO$ 也可根据混淆矩阵计算。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.14814">相关论文：WinCLIP</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2304.02643">相关论文：SAM</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2401.12665">论文链接</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/Lszcoding/ClipSAM">代码链接（未上传）</a></p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%A7%91%E7%A0%94/">科研</a></div><div class="post_share"><div class="social-share" data-image="https://telegraph-image-9wl.pages.dev/file/610c334d0084c2b8c8875.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer=""></script></div></div><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/02/23/%E7%A7%91%E7%A0%94-%E5%BC%95%E7%94%A8/" title="论文引用记录"><img class="cover" src="https://telegraph-image-9wl.pages.dev/file/0eba3bbe1d962a623a857.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-23</div><div class="title">论文引用记录</div></div></a></div><div><a href="/2024/03/19/%E7%A7%91%E7%A0%94-%E5%9B%A2%E9%98%9F/" title="团队"><img class="cover" src="https://telegraph-image-9wl.pages.dev/file/0a487bb83f3024d2e750c.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-19</div><div class="title">团队</div></div></a></div><div><a href="/2024/02/20/%E7%A7%91%E7%A0%94-1-AnomalyCLIP/" title="AnomalyCLIP：Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"><img class="cover" src="https://telegraph-image-9wl.pages.dev/file/bde3dbfce428b9d30dc25.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-20</div><div class="title">AnomalyCLIP：Object-agnostic Prompt Learning for Zero-shot Anomaly Detection</div></div></a></div><div><a href="/2024/03/16/%E7%A7%91%E7%A0%94-12-Survey2024/" title="Deep Industrial Image Anomaly Detection：A Survey"><img class="cover" src="https://telegraph-image-9wl.pages.dev/file/017edd72f0a5a9500da0d.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-16</div><div class="title">Deep Industrial Image Anomaly Detection：A Survey</div></div></a></div><div><a href="/2024/03/17/%E7%A7%91%E7%A0%94-%E6%A8%A1%E7%89%88/" title="模版"><img class="cover" src="https://telegraph-image-9wl.pages.dev/file/a37eea9b3846997e38fe5.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-17</div><div class="title">模版</div></div></a></div><div><a href="/2024/03/19/%E7%A7%91%E7%A0%94-14-Text-Guided-Variational-Image-Generation/" title="Text-Guided Variational Image Generation for Industrial Anomaly Detection and Segmentation"><img class="cover" src="https://telegraph-image-9wl.pages.dev/file/590d46d735bef6f03ae35.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-19</div><div class="title">Text-Guided Variational Image Generation for Industrial Anomaly Detection and Segmentation</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#ClipSAM"><span class="toc-number">1.</span> <span class="toc-text">ClipSAM</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E9%97%AE%E9%A2%98"><span class="toc-number">1.1.</span> <span class="toc-text">1. 问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-ZSAD%EF%BC%88%E9%9B%B6%E6%A0%B7%E6%9C%AC%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%EF%BC%89%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.1.1.</span> <span class="toc-text">1. ZSAD（零样本异常检测）任务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-CLIP-%E7%94%A8%E4%BA%8EZSAS%E9%97%AE%E9%A2%98"><span class="toc-number">1.1.2.</span> <span class="toc-text">2. CLIP 用于ZSAS问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-SAM-%E7%94%A8%E4%BA%8EZSAS%E9%97%AE%E9%A2%98"><span class="toc-number">1.1.3.</span> <span class="toc-text">3. SAM 用于ZSAS问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%88%9B%E6%96%B0"><span class="toc-number">1.2.</span> <span class="toc-text">2. 创新</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-CLIP-%E5%92%8C-SAM-%E5%8D%8F%E5%90%8C"><span class="toc-number">1.2.1.</span> <span class="toc-text">1. CLIP 和 SAM 协同</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%BB%9F%E4%B8%80%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%B7%A8%E6%A8%A1%E6%80%81%E4%BA%A4%E4%BA%92-UMCI-%E6%A8%A1%E5%9D%97"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.  统一多尺度跨模态交互(UMCI)模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%A4%9A%E7%BA%A7%E6%8E%A9%E7%A0%81%E7%BB%86%E5%8C%96-MMR-%E6%A8%A1%E5%9D%97"><span class="toc-number">1.2.3.</span> <span class="toc-text">3. 多级掩码细化(MMR)模块</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%96%B9%E6%B3%95"><span class="toc-number">1.3.</span> <span class="toc-text">3. 方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-CLIP-%E9%83%A8%E5%88%86"><span class="toc-number">1.3.1.</span> <span class="toc-text">1.CLIP 部分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%BB%9F%E4%B8%80%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%B7%A8%E6%A8%A1%E6%80%81%E4%BA%A4%E4%BA%92-UMCI-%E6%A8%A1%E5%9D%97-1"><span class="toc-number">1.3.2.</span> <span class="toc-text">2.统一多尺度跨模态交互(UMCI)模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-SAM%E9%83%A8%E5%88%86%EF%BC%8C%E5%A4%9A%E7%BA%A7%E6%8E%A9%E7%A0%81%E7%BB%86%E5%8C%96-MMC"><span class="toc-number">1.3.3.</span> <span class="toc-text">3. SAM部分，多级掩码细化(MMC)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.3.4.</span> <span class="toc-text">4. 损失函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E7%BB%93%E6%9E%9C"><span class="toc-number">1.4.</span> <span class="toc-text">4. 结果</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">©2024 By Just花语</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat-btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js"></script><div class="js-pjax"></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/click-heart.min.js" async="async" mobile="true"></script><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div></body></html>